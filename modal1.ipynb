{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/apoorvwatsky/miraclvc1?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.13G/5.13G [05:19<00:00, 17.2MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"apoorvwatsky/miraclvc1\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imutils\n",
    "import dlib \n",
    "import cv2 \n",
    "\n",
    "import imageio\n",
    "from imutils import face_utils\n",
    "import multiprocessing\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "  x = rect.left()\n",
    "  y = rect.top()\n",
    "  w = rect.right() - x\n",
    "  h = rect.bottom() - y\n",
    "  return (x, y, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "  coords = np.zeros((68, 2), dtype=dtype)\n",
    "  for i in range(0, 68):\n",
    "    coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "  return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('/home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "@functools.lru_cache(maxsize=None)  # Use caching for crop_and_save_image\n",
    "def crop_and_save_image(img_path, write_img_path):\n",
    "    try:\n",
    "        image = cv2.imread(img_path)\n",
    "        image = imutils.resize(image, width=500)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        rects = detector(gray, 1)\n",
    "        if len(rects) > 1:\n",
    "            print(\"ERROR: more than one face detected\")\n",
    "            return\n",
    "        if len(rects) < 1:\n",
    "            print(\"ERROR: no faces detected\")\n",
    "            return\n",
    "\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            name, i, j = 'mouth', 48, 68\n",
    "            clone = gray.copy()\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))\n",
    "            roi = gray[y:y + h, x:x + w]\n",
    "            roi = imutils.resize(roi, width=250, inter=cv2.INTER_CUBIC)\n",
    "            cv2.imwrite('cropped/' + write_img_path, roi)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: Image file not found: {img_path}\")\n",
    "        return  # Continue with the next image\n",
    "\n",
    "\n",
    "\n",
    "def process_person(person_ID):\n",
    "    for data_type in data_types:\n",
    "        for phrase_ID in folder_enum:\n",
    "            for instance_ID in instances:\n",
    "                directory = '/home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3/dataset/dataset/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "                dir_temp = person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "               \n",
    "                if not os.path.exists(directory):\n",
    "                    print(f\"WARNING: Directory not found: {directory}\")\n",
    "                    continue\n",
    "                \n",
    "                filelist = os.listdir(directory)\n",
    "\n",
    "                for img_name in filelist:\n",
    "                    if img_name.startswith('color'):\n",
    "                        img_path = directory + img_name\n",
    "                        write_img_path = dir_temp + img_name\n",
    "                        \n",
    "                        if not os.path.exists(img_path):  # Check if image file exists\n",
    "                            print(f\"WARNING: Image file not found: {img_path}\")\n",
    "                            continue  # Skip this image and continue with the next\n",
    "\n",
    "                        # Check if the image has already been cropped and cached\n",
    "                        if not os.path.exists('cropped/' + write_img_path):\n",
    "                            try:\n",
    "                                crop_and_save_image(img_path, write_img_path)  # Cache the result\n",
    "                            except Exception as e:\n",
    "                                print(f\"ERROR: Failed to process image {img_path}: {e}\")\n",
    "                                continue\n",
    "\n",
    "def crop_all_persons():\n",
    "    if not os.path.exists('cropped'):\n",
    "        os.mkdir('cropped')\n",
    "    \n",
    "    for person_ID in people:\n",
    "        if not os.path.exists('cropped/' + person_ID):\n",
    "            os.mkdir('cropped/' + person_ID + '/')\n",
    "        \n",
    "        for data_type in data_types:\n",
    "            if not os.path.exists('cropped/' + person_ID + '/' + data_type):\n",
    "                os.mkdir('cropped/' + person_ID + '/' + data_type)\n",
    "            \n",
    "            for phrase_ID in folder_enum:\n",
    "                if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID):\n",
    "                    os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID)\n",
    "                    \n",
    "                for instance_ID in instances:\n",
    "                    if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID):\n",
    "                        os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID)\n",
    "    # Use multiprocessing to process people in parallel\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(process_person, people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3/dataset/dataset')\n",
    "predictor = dlib.shape_predictor('/home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\n",
    "data_types = ['words']\n",
    "folder_enum = ['01','02','03','04','05']\n",
    "instances = ['01','02']\n",
    "\n",
    "words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']          \n",
    "words_di = {i:words[i] for i in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def crop_one_person():      \n",
    "    \n",
    "#     people = ['F01','F02','F04']\n",
    "#     data_types = ['words']\n",
    "#     folder_enum = ['01','02']\n",
    "#     instances = ['01','02']\n",
    "\n",
    "    i = 1\n",
    "    for person_ID in people:\n",
    "        if not os.path.exists('cropped/' + person_ID ):\n",
    "            os.mkdir('cropped/' + person_ID + '/')\n",
    "\n",
    "        for data_type in data_types:\n",
    "            if not os.path.exists('cropped/' + person_ID + '/' + data_type):\n",
    "                os.mkdir('cropped/' + person_ID + '/' + data_type)\n",
    "\n",
    "            for phrase_ID in folder_enum:\n",
    "                if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID):\n",
    "                    # F01/phrases/01\n",
    "                    os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID)\n",
    "\n",
    "                for instance_ID in instances:\n",
    "                    # F01/phrases/01/01\n",
    "                    directory = '/home/vaibhav/.cache/kagglehub/datasets/apoorvwatsky/miraclvc1/versions/3/dataset/dataset/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "                    dir_temp = person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "    #                 print(directory)\n",
    "                    filelist = os.listdir(directory)\n",
    "                    if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID):\n",
    "                        os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID)\n",
    "\n",
    "                        for img_name in filelist:\n",
    "                            if img_name.startswith('color'):\n",
    "                                image = imageio.imread(directory + '' + img_name)\n",
    "                                try:\n",
    "                                  crop_and_save_image(image, directory + '' + img_name,dir_temp + '' + img_name, img_name)\n",
    "                                except:\n",
    "                                  continue\n",
    "\n",
    "    print(f'Iteration : {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18329/2744066801.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(directory + '' + img_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Iteration : 1\n",
      "Average time over 7 iterations :  0.501004832131522\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "os.mkdir('cropped')\n",
    "times = 0\n",
    "for _ in range(7):\n",
    "    t1 = time.time()\n",
    "    crop_one_person()\n",
    "    t2 = time.time()\n",
    "    times += (t2 - t1)\n",
    "\n",
    "print(\"Average time over 7 iterations : \", times/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 22\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "MAX_WIDTH = 100\n",
    "MAX_HEIGHT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F01. Time taken : 0.0013263225555419922 secs.\n",
      "Finished reading images for person F02. Time taken : 0.0004012584686279297 secs.\n",
      "Finished reading images for person F04. Time taken : 0.00022673606872558594 secs.\n",
      "Finished reading images for person F05. Time taken : 0.00023412704467773438 secs.\n",
      "Finished reading images for person F06. Time taken : 0.0004355907440185547 secs.\n",
      "Finished reading images for person F07. Time taken : 0.00022482872009277344 secs.\n",
      "Finished reading images for person F08. Time taken : 0.00026702880859375 secs.\n",
      "Finished reading images for person F09. Time taken : 0.0002396106719970703 secs.\n",
      "Finished reading images for person F10. Time taken : 0.00023365020751953125 secs.\n",
      "Finished reading images for person F11. Time taken : 0.0002033710479736328 secs.\n",
      "Finished reading images for person M01. Time taken : 0.00020241737365722656 secs.\n",
      "Finished reading images for person M02. Time taken : 0.00020742416381835938 secs.\n",
      "Finished reading images for person M04. Time taken : 0.00024056434631347656 secs.\n",
      "Finished reading images for person M07. Time taken : 0.0002980232238769531 secs.\n",
      "Finished reading images for person M08. Time taken : 0.0001819133758544922 secs.\n",
      "Time taken for creating constant size 3D Tensors from those cropped lip regions : 0.00560307502746582 secs.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "UNSEEN_VALIDATION_SPLIT = ['F07', 'M02']\n",
    "UNSEEN_TEST_SPLIT = ['F04','M01']\n",
    "\n",
    "directory = \"/home/vaibhav/project/cropped\"\n",
    "\n",
    "for person_id in people:\n",
    "    tx1 = time.time()\n",
    "    for data_type in data_types:\n",
    "        for word_index, word in enumerate(folder_enum):\n",
    "#             print(f\"Word : '{words[word_index]}'\")\n",
    "            for iteration in instances:\n",
    "                path = os.path.join(directory, person_id, data_type, word, iteration)\n",
    "                filelist = sorted(os.listdir(path + '/'))\n",
    "                sequence = [] \n",
    "                for img_name in filelist:\n",
    "                    if img_name.startswith('color'):\n",
    "                        image = imageio.imread(path + '/' + img_name)\n",
    "                        image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\n",
    "                        image = 255 * image\n",
    "                        # Convert to integer data type pixels.\n",
    "                        image = image.astype(np.uint8)\n",
    "                        sequence.append(image)                        \n",
    "                pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]                            \n",
    "                sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
    "                #sequence = np.array(sequence)\n",
    "                                \n",
    "                if person_id in UNSEEN_TEST_SPLIT:\n",
    "                    X_test.append(sequence)\n",
    "                    y_test.append(word_index)\n",
    "                elif person_id in UNSEEN_VALIDATION_SPLIT:\n",
    "                    X_val.append(sequence)\n",
    "                    y_val.append(word_index)\n",
    "                else:\n",
    "                    X_train.append(sequence)\n",
    "                    y_train.append(word_index)    \n",
    "    tx2 = time.time()\n",
    "    print(f'Finished reading images for person {person_id}. Time taken : {tx2 - tx1} secs.')    \n",
    "    \n",
    "t2 = time.time()\n",
    "print(f\"Time taken for creating constant size 3D Tensors from those cropped lip regions : {t2 - t1} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 22, 100, 100)\n",
      "(20, 22, 100, 100)\n",
      "(20, 22, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110,)\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_it(X):\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True)\n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
    "\n",
    "    # Calculate the range and replace zero values with epsilon to avoid division by zero\n",
    "    range_values = np.where((v_max - v_min) == 0, np.finfo(float).eps, v_max - v_min)\n",
    "\n",
    "    # Normalize the data\n",
    "    X_normalized = np.where(range_values == 0, 0, (X - v_min) / range_values)\n",
    "\n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 20:30:10.360732: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 20:30:10.481499: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 20:30:10.565628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742914810.636878   18329 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742914810.659403   18329 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742914810.832330   18329 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742914810.832369   18329 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742914810.832372   18329 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742914810.832374   18329 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-25 20:30:10.852410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize_it(X_train)\n",
    "X_val = normalize_it(X_val)\n",
    "X_test = normalize_it(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=4)\n",
    "X_val = np.expand_dims(X_val, axis=4)\n",
    "X_test = np.expand_dims(X_test, axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 22, 100, 100, 1)\n",
      "(20, 22, 100, 100, 1)\n",
      "(20, 22, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "E0000 00:00:1742914841.726370   18329 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1742914841.726849   18329 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-03-25 20:30:41.797313: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2025-03-25 20:30:41.879105: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2025-03-25 20:30:41.968300: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">221,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">75,501,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,390,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,250</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m64\u001b[0m) │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m128\u001b[0m) │       \u001b[38;5;34m221,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m) │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv3d_3 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m512\u001b[0m) │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling3d_3 (\u001b[38;5;33mMaxPooling3D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m75,501,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m8,390,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m10,250\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,617,738</span> (330.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,617,738\u001b[0m (330.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,617,738</span> (330.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,617,738\u001b[0m (330.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 22, 100, 100, 1)\n",
      "(20, 10)\n",
      "(110, 22, 100, 100, 1)\n",
      "(110, 10)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st layer group\n",
    "model.add(Conv3D(64, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(256, (2, 2, 2), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(512, (1, 1, 1), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(1, 1, 1), strides=2))\n",
    "\n",
    "model.add((Flatten()))\n",
    "\n",
    "# # FC layers group\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 20:30:54.046483: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n",
      "2025-03-25 20:30:54.046545: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 301989888 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.1543 - loss: 2.3022 - val_accuracy: 0.2000 - val_loss: 2.3008\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.1908 - loss: 2.3005 - val_accuracy: 0.2000 - val_loss: 2.2994\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.2122 - loss: 2.2991 - val_accuracy: 0.2000 - val_loss: 2.2982\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.1397 - loss: 2.2980 - val_accuracy: 0.2000 - val_loss: 2.2972\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.2145 - loss: 2.2969 - val_accuracy: 0.2000 - val_loss: 2.2962\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.2056 - loss: 2.2960 - val_accuracy: 0.2000 - val_loss: 2.2953\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.2439 - loss: 2.2951 - val_accuracy: 0.2000 - val_loss: 2.2945\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 9s/step - accuracy: 0.2368 - loss: 2.2943 - val_accuracy: 0.2000 - val_loss: 2.2937\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.1794 - loss: 2.2936 - val_accuracy: 0.2000 - val_loss: 2.2930\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1935 - loss: 2.2928 - val_accuracy: 0.2000 - val_loss: 2.2923\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2398 - loss: 2.2921 - val_accuracy: 0.2000 - val_loss: 2.2917\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.1505 - loss: 2.2916 - val_accuracy: 0.2000 - val_loss: 2.2910\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 8s/step - accuracy: 0.1902 - loss: 2.2909 - val_accuracy: 0.2000 - val_loss: 2.2904\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.1945 - loss: 2.2903 - val_accuracy: 0.2000 - val_loss: 2.2898\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1975 - loss: 2.2897 - val_accuracy: 0.2000 - val_loss: 2.2893\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1602 - loss: 2.2892 - val_accuracy: 0.2000 - val_loss: 2.2887\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2029 - loss: 2.2886 - val_accuracy: 0.2000 - val_loss: 2.2882\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1630 - loss: 2.2881 - val_accuracy: 0.2000 - val_loss: 2.2877\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.1672 - loss: 2.2876 - val_accuracy: 0.2000 - val_loss: 2.2871\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2365 - loss: 2.2870 - val_accuracy: 0.2000 - val_loss: 2.2867\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2065 - loss: 2.2865 - val_accuracy: 0.2000 - val_loss: 2.2862\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.2376 - loss: 2.2860 - val_accuracy: 0.2000 - val_loss: 2.2857\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.2500 - loss: 2.2856 - val_accuracy: 0.2000 - val_loss: 2.2852\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2419 - loss: 2.2851 - val_accuracy: 0.2000 - val_loss: 2.2848\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1858 - loss: 2.2847 - val_accuracy: 0.2000 - val_loss: 2.2844\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1707 - loss: 2.2843 - val_accuracy: 0.2000 - val_loss: 2.2839\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2229 - loss: 2.2838 - val_accuracy: 0.2000 - val_loss: 2.2835\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2013 - loss: 2.2834 - val_accuracy: 0.2000 - val_loss: 2.2831\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2117 - loss: 2.2830 - val_accuracy: 0.2000 - val_loss: 2.2827\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2245 - loss: 2.2826 - val_accuracy: 0.2000 - val_loss: 2.2823\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2324 - loss: 2.2822 - val_accuracy: 0.2000 - val_loss: 2.2819\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2008 - loss: 2.2818 - val_accuracy: 0.2000 - val_loss: 2.2815\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1770 - loss: 2.2814 - val_accuracy: 0.2000 - val_loss: 2.2811\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1858 - loss: 2.2810 - val_accuracy: 0.2000 - val_loss: 2.2807\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1369 - loss: 2.2807 - val_accuracy: 0.2000 - val_loss: 2.2804\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.2003 - loss: 2.2803 - val_accuracy: 0.2000 - val_loss: 2.2800\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1270 - loss: 2.2800 - val_accuracy: 0.2000 - val_loss: 2.2796\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1723 - loss: 2.2796 - val_accuracy: 0.2000 - val_loss: 2.2793\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2341 - loss: 2.2791 - val_accuracy: 0.2000 - val_loss: 2.2789\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2116 - loss: 2.2788 - val_accuracy: 0.2000 - val_loss: 2.2786\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1617 - loss: 2.2786 - val_accuracy: 0.2000 - val_loss: 2.2782\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1915 - loss: 2.2782 - val_accuracy: 0.2000 - val_loss: 2.2779\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2419 - loss: 2.2778 - val_accuracy: 0.2000 - val_loss: 2.2776\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1547 - loss: 2.2775 - val_accuracy: 0.2000 - val_loss: 2.2772\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2111 - loss: 2.2772 - val_accuracy: 0.2000 - val_loss: 2.2769\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2029 - loss: 2.2768 - val_accuracy: 0.2000 - val_loss: 2.2766\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1711 - loss: 2.2765 - val_accuracy: 0.2000 - val_loss: 2.2763\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1563 - loss: 2.2763 - val_accuracy: 0.2000 - val_loss: 2.2760\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1692 - loss: 2.2759 - val_accuracy: 0.2000 - val_loss: 2.2757\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2152 - loss: 2.2756 - val_accuracy: 0.2000 - val_loss: 2.2753\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2173 - loss: 2.2753 - val_accuracy: 0.2000 - val_loss: 2.2750\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.2270 - loss: 2.2750 - val_accuracy: 0.2000 - val_loss: 2.2747\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1961 - loss: 2.2747 - val_accuracy: 0.2000 - val_loss: 2.2744\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2136 - loss: 2.2744 - val_accuracy: 0.2000 - val_loss: 2.2741\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2054 - loss: 2.2741 - val_accuracy: 0.2000 - val_loss: 2.2738\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1950 - loss: 2.2737 - val_accuracy: 0.2000 - val_loss: 2.2736\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1726 - loss: 2.2735 - val_accuracy: 0.2000 - val_loss: 2.2733\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1547 - loss: 2.2732 - val_accuracy: 0.2000 - val_loss: 2.2730\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2094 - loss: 2.2729 - val_accuracy: 0.2000 - val_loss: 2.2727\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2096 - loss: 2.2727 - val_accuracy: 0.2000 - val_loss: 2.2724\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2163 - loss: 2.2724 - val_accuracy: 0.2000 - val_loss: 2.2721\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1372 - loss: 2.2721 - val_accuracy: 0.2000 - val_loss: 2.2719\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1986 - loss: 2.2718 - val_accuracy: 0.2000 - val_loss: 2.2716\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1428 - loss: 2.2716 - val_accuracy: 0.2000 - val_loss: 2.2713\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2247 - loss: 2.2713 - val_accuracy: 0.2000 - val_loss: 2.2711\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1420 - loss: 2.2710 - val_accuracy: 0.2000 - val_loss: 2.2708\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1455 - loss: 2.2708 - val_accuracy: 0.2000 - val_loss: 2.2705\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2474 - loss: 2.2705 - val_accuracy: 0.2000 - val_loss: 2.2703\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.1437 - loss: 2.2702 - val_accuracy: 0.2000 - val_loss: 2.2700\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2413 - loss: 2.2699 - val_accuracy: 0.2000 - val_loss: 2.2698\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2147 - loss: 2.2697 - val_accuracy: 0.2000 - val_loss: 2.2695\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2085 - loss: 2.2694 - val_accuracy: 0.2000 - val_loss: 2.2692\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1414 - loss: 2.2692 - val_accuracy: 0.2000 - val_loss: 2.2690\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1670 - loss: 2.2690 - val_accuracy: 0.2000 - val_loss: 2.2687\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2341 - loss: 2.2686 - val_accuracy: 0.2000 - val_loss: 2.2685\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2507 - loss: 2.2684 - val_accuracy: 0.2000 - val_loss: 2.2682\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 8s/step - accuracy: 0.2013 - loss: 2.2681 - val_accuracy: 0.2000 - val_loss: 2.2680\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2194 - loss: 2.2679 - val_accuracy: 0.2000 - val_loss: 2.2678\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1357 - loss: 2.2678 - val_accuracy: 0.2000 - val_loss: 2.2675\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1841 - loss: 2.2675 - val_accuracy: 0.2000 - val_loss: 2.2673\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1563 - loss: 2.2672 - val_accuracy: 0.2000 - val_loss: 2.2670\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2036 - loss: 2.2669 - val_accuracy: 0.2000 - val_loss: 2.2668\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1921 - loss: 2.2668 - val_accuracy: 0.2000 - val_loss: 2.2666\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1720 - loss: 2.2665 - val_accuracy: 0.2000 - val_loss: 2.2663\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2025 - loss: 2.2663 - val_accuracy: 0.2000 - val_loss: 2.2661\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 8s/step - accuracy: 0.1979 - loss: 2.2661 - val_accuracy: 0.2000 - val_loss: 2.2659\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1870 - loss: 2.2658 - val_accuracy: 0.2000 - val_loss: 2.2656\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2350 - loss: 2.2655 - val_accuracy: 0.2000 - val_loss: 2.2654\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2030 - loss: 2.2653 - val_accuracy: 0.2000 - val_loss: 2.2652\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1878 - loss: 2.2651 - val_accuracy: 0.2000 - val_loss: 2.2649\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1652 - loss: 2.2649 - val_accuracy: 0.2000 - val_loss: 2.2647\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2320 - loss: 2.2646 - val_accuracy: 0.2000 - val_loss: 2.2645\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1857 - loss: 2.2645 - val_accuracy: 0.2000 - val_loss: 2.2643\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1898 - loss: 2.2643 - val_accuracy: 0.2000 - val_loss: 2.2640\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.2486 - loss: 2.2640 - val_accuracy: 0.2000 - val_loss: 2.2638\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2061 - loss: 2.2638 - val_accuracy: 0.2000 - val_loss: 2.2636\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2111 - loss: 2.2635 - val_accuracy: 0.2000 - val_loss: 2.2634\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.1802 - loss: 2.2634 - val_accuracy: 0.2000 - val_loss: 2.2632\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 8s/step - accuracy: 0.2363 - loss: 2.2631 - val_accuracy: 0.2000 - val_loss: 2.2630\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 8s/step - accuracy: 0.1417 - loss: 2.2629 - val_accuracy: 0.2000 - val_loss: 2.2627\n",
      "\n",
      "Training time : 5483.020743846893 secs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=16)\n",
    "t2 = time.time()\n",
    "print()\n",
    "print(f\"Training time : {t2 - t1} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
